use crate::api::models::groups::GroupResponse;
use crate::db::models::deployments::{
    DeploymentDBResponse, ModelType, ProviderPricing, ProviderPricingUpdate, TokenPricing, TokenPricingUpdate,
};
use crate::types::{DeploymentId, InferenceEndpointId, UserId};
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};
use serde_with::rust::double_option;
use utoipa::{IntoParams, ToSchema};

/// Query parameters for listing deployed models
/// TODO: Pagination
#[derive(Debug, Deserialize, IntoParams, ToSchema)]
pub struct ListModelsQuery {
    /// Filter by inference endpoint ID
    #[param(value_type = Option<String>, format = "uuid")]
    #[schema(value_type = Option<String>, format = "uuid")]
    pub endpoint: Option<InferenceEndpointId>,
    /// Include related data (comma-separated: "groups", "metrics")
    pub include: Option<String>,
    /// Show deleted models when true, non-deleted when false, all when not specified (admin only for deleted=true)
    pub deleted: Option<bool>,
    /// Show inactive models when true, active when false, all when not specified (admin only for inactive=true)
    pub inactive: Option<bool>,
    /// Filter to only models the current user can access (defaults to false for admins, true for users)
    pub accessible: Option<bool>,
}

/// Query parameters for getting a single deployed model
#[derive(Debug, Deserialize, IntoParams, ToSchema)]
pub struct GetModelQuery {
    /// Show deleted model when true, 404 when false/unspecified if model is deleted
    pub deleted: Option<bool>,
    /// Show inactive model when true, 404 when false/unspecified if model is inactive
    pub inactive: Option<bool>,
}

/// Time series point for model activity sparklines
#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]
pub struct ModelTimeSeriesPoint {
    pub timestamp: DateTime<Utc>,
    pub requests: i64,
}

/// Model metrics for display on model cards
#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]
pub struct ModelMetrics {
    /// Average latency across all requests in milliseconds
    pub avg_latency_ms: Option<f64>,
    /// Total number of requests made to this model
    pub total_requests: i64,
    /// Total input tokens processed by this model
    pub total_input_tokens: i64,
    /// Total output tokens generated by this model
    pub total_output_tokens: i64,
    /// When the model was last active (last request timestamp)
    pub last_active_at: Option<DateTime<Utc>>,
    /// Recent activity for sparklines (last 24 hours, hourly buckets)
    pub time_series: Option<Vec<ModelTimeSeriesPoint>>,
}

/// The data required to create a new model.
#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]
pub struct DeployedModelCreate {
    /// The actual model identifier (e.g., "gpt-4", "claude-3-sonnet")
    pub model_name: String,
    /// User-friendly alias (e.g., "GPT-4 Turbo", "Claude Sonnet") - defaults to model_name if not provided
    pub alias: Option<String>,
    /// Inference endpoint ID where the model is hosted
    #[schema(value_type = String, format = "uuid")]
    pub hosted_on: InferenceEndpointId,
    /// Optional description of the model
    pub description: Option<String>,
    /// Optional model type (Chat or Embeddings)
    pub model_type: Option<ModelType>,
    /// Optional array of model capabilities
    pub capabilities: Option<Vec<String>>,
    /// Global per-model rate limit: requests per second (null = no limit)
    pub requests_per_second: Option<f32>,
    /// Global per-model rate limit: maximum burst size (null = no limit)
    pub burst_size: Option<i32>,
    /// Customer-facing pricing rates
    pub pricing: Option<TokenPricing>,
    /// Provider/downstream pricing details (admin only)
    pub downstream_pricing: Option<ProviderPricing>,
}

/// The data required to update a specific model.
#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]
pub struct DeployedModelUpdate {
    pub alias: Option<String>,
    pub description: Option<Option<String>>,
    pub model_type: Option<Option<ModelType>>,
    pub capabilities: Option<Option<Vec<String>>>,
    /// Global per-model rate limit: requests per second (null = no change, Some(None) = remove limit)
    #[serde(default, skip_serializing_if = "Option::is_none", with = "double_option")]
    pub requests_per_second: Option<Option<f32>>,
    /// Global per-model rate limit: maximum burst size (null = no change, Some(None) = remove limit)
    #[serde(default, skip_serializing_if = "Option::is_none", with = "double_option")]
    pub burst_size: Option<Option<i32>>,
    /// Customer-facing pricing rates partial updates (null = no change, Some(pricing_update) = partial update)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub pricing: Option<TokenPricingUpdate>,
    /// Provider/downstream pricing details partial updates (null = no change, Some(pricing_update) = partial update)
    #[serde(default, skip_serializing_if = "Option::is_none")]
    pub downstream_pricing: Option<ProviderPricingUpdate>,
}

/// A request to update a specific model (i.e. bundle a `DeployedModelUpdate` with a model id).
#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]
pub struct DeployedModelUpdateRequest {
    #[schema(value_type = String, format = "uuid")]
    pub id: DeploymentId,
    pub deployed_model: DeployedModelUpdate,
}

/// API response for a deployed model
#[derive(Debug, Clone, Serialize, Deserialize, ToSchema)]
pub struct DeployedModelResponse {
    #[schema(value_type = String, format = "uuid")]
    pub id: DeploymentId,
    pub model_name: String,
    pub alias: String,
    pub description: Option<String>,
    pub model_type: Option<ModelType>,
    pub capabilities: Option<Vec<String>>,
    #[schema(value_type = String, format = "uuid")]
    pub created_by: UserId,
    #[schema(value_type = String, format = "uuid")]
    pub hosted_on: InferenceEndpointId,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    /// Global per-model rate limit: requests per second (null = no limit)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub requests_per_second: Option<f32>,
    /// Global per-model rate limit: maximum burst size (null = no limit)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub burst_size: Option<i32>,
    /// Groups that have access to this model (only included if requested)
    /// Note: no_recursion is important! utoipa will panic at runtime, because it overflows the
    /// stack trying to follow the relationship.
    #[serde(skip_serializing_if = "Option::is_none")]
    #[schema(no_recursion)]
    pub groups: Option<Vec<GroupResponse>>,
    /// Model usage metrics (only included if requested)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub metrics: Option<ModelMetrics>,
    /// Customer-facing pricing rates (only included if requested)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub pricing: Option<TokenPricing>,
    /// Provider/downstream pricing details (only included if requested and user has Pricing::ReadAll)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub downstream_pricing: Option<ProviderPricing>,
}

impl From<DeploymentDBResponse> for DeployedModelResponse {
    fn from(db: DeploymentDBResponse) -> Self {
        Self {
            id: db.id,
            model_name: db.model_name,
            alias: db.alias,
            description: db.description,
            model_type: db.model_type,
            capabilities: db.capabilities,
            created_by: db.created_by,
            hosted_on: db.hosted_on,
            created_at: db.created_at,
            updated_at: db.updated_at,
            requests_per_second: db.requests_per_second,
            burst_size: db.burst_size,
            groups: None,             // By default, relationships are not included
            metrics: None,            // By default, metrics are not included
            pricing: None,            // By default, pricing is not included (opt-in via include)
            downstream_pricing: None, // By default, downstream pricing is not included
        }
    }
}

impl DeployedModelResponse {
    /// Create a response with groups included
    pub fn with_groups(mut self, groups: Vec<GroupResponse>) -> Self {
        self.groups = Some(groups);
        self
    }

    /// Create a response with metrics included
    pub fn with_metrics(mut self, metrics: ModelMetrics) -> Self {
        self.metrics = Some(metrics);
        self
    }

    /// Create a response with customer pricing included
    pub fn with_pricing(mut self, pricing: Option<TokenPricing>) -> Self {
        self.pricing = pricing;
        self
    }

    /// Create a response with downstream pricing included (admin only)
    pub fn with_downstream_pricing(mut self, downstream_pricing: Option<ProviderPricing>) -> Self {
        self.downstream_pricing = downstream_pricing;
        self
    }

    /// Mask rate limiting information (sets to None for users without permission)
    pub fn mask_rate_limiting(mut self) -> Self {
        self.requests_per_second = None;
        self.burst_size = None;
        self
    }
}
