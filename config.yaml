# Clay configuration
# This is the default configuration file.

# Server configuration
# To advertise publically, set to "0.0.0.0", or the specific network interface
# you've exposed.
host: "0.0.0.0"
port: 3001

# Database configuration
database:
  # Configure connectivity to an external postgres database here
  type: external
  url: postgres://postgres:password@localhost:5432/dwctl
  # We also bundle a copy of postgres with dwctl. It's launched on a random
  # port, and data is stored in $HOME/.dwctl_data/ To have data persist
  # across restarts, set persistent=true.
  # We strongly recommend setting up external postgres in production!
  # type: embedded
  # persistent: true

# Admin user email - will be created on first startup
admin_email: "test@doubleword.ai"
# TODO: Change this in production!
admin_password: "hunter2"

# Secret key for jwt signing.
# TODO: Change this in production
secret_key: insecure-change-in-production

# Model sources - inference endpoints to connect to
# Uncomment and configure as needed
model_sources: []

# Example configurations:
# model_sources:
#   # OpenAI API
#   - name: "openai"
#     url: "https://api.openai.com"
#     api_key: "sk-..."  # Required for model sync
#
#   # Internal model server (no auth required)
#   - name: "internal"
#     url: "http://localhost:8080"

# Frontend metadata
metadata:
  region: "UK South"
  organization: "ACME Corp"

# Authentication configuration
auth:
  # Native username/password authentication
  native:
    enabled: true # Enable native login system
    allow_registration: true
    password:
      min_length: 8
      max_length: 64
    session:
      timeout: "24h"
      cookie_name: "dwctl_session"
      cookie_secure: true
      cookie_same_site: "strict"

  # Proxy header authentication
  # Accepts user identity from HTTP headers set by an upstream authentication proxy
  # (e.g., oauth2-proxy, Vouch, Authentik, Auth0)
  #
  # Two modes:
  #   Single header: Send only header_name with user's email (must be unique)
  #   Dual header: Send both header_name (IdP identifier) and email_header_name (email)
  #                Allows multiple accounts per email from different identity providers
  proxy_header:
    enabled: true

    # header_name: User identifier or email
    # Single header mode: User's email (e.g., "user@example.com")
    # Dual header mode: Unique identifier from IdP (e.g., "github|user123", "google-oauth2|456")
    header_name: "x-doubleword-user"

    # email_header_name: User's email address (optional, enables dual header mode)
    # If provided: Enables federated identity with (email, external_user_id) uniqueness
    # If omitted: Uses header_name value as email (single header mode, email must be unique)
    email_header_name: "x-doubleword-email"

    # auto_create_users: Automatically create users on first login
    auto_create_users: true

  # Security settings
  security:
    enable_csrf: true
    jwt_expiry: "1h"
    cors:
      allowed_origins:
        - "http://localhost:5173" # Development frontend (Vite)
        - "https://localhost" # Local HTTPS
      allow_credentials: true
      max_age: 3600 # Cache preflight requests for 1 hour

# Credits configuration
credits:
  # Initial credits given to standard users when they are created
  # Set to 0 to disable initial credits (users start with no credits)
  # Example: 100.00 gives users 100 credits on registration
  initial_credits_for_standard_users: 0

# Optional feature toggles
enable_metrics: true # Enable Prometheus metrics endpoint
enable_request_logging: true # Enable request/response logging to database
# Note: Environment variables can override top level setting, as long as they're supplied with the DWCTL_ prefix:
# DWCTL_PORT=8080
#
# The exception is DATABASE_URL:
# DATABASE_URL=postgres://prod@db:5432/my_database
#
# For arrays like model_sources, use environment-specific config files
# (e.g., config.production.yaml) rather than env vars.

# Batches API configuration
batches:
  # Enable batches API endpoints (/files, /batches)
  # When disabled, these endpoints will not be available (default: true)
  enabled: true

  # Daemon configuration for processing batch requests
  daemon:
    # Controls when the batch processing daemon runs
    # - "leader": Only run on the elected leader instance (default, recommended for multi-instance deployments)
    # - "always": Run on all instances (use for single-instance deployments)
    # - "never": Never run the daemon (useful for testing or when using external processors)
    enabled: leader

    # Performance & Concurrency Settings
    claim_batch_size: 100 # Maximum number of requests to claim in each iteration
    default_model_concurrency: 10 # Default concurrent requests per model
    claim_interval_ms: 1000 # Milliseconds to sleep between claim iterations

    # Retry & Backoff Settings
    max_retries: 5 # Maximum retry attempts before giving up
    backoff_ms: 1000 # Initial backoff duration in milliseconds
    backoff_factor: 2 # Exponential backoff multiplier
    max_backoff_ms: 10000 # Maximum backoff duration in milliseconds

    # Timeout Settings
    timeout_ms: 600000 # Timeout per request attempt (10 minutes)
    claim_timeout_ms: 60000 # Max time in "claimed" state before auto-unclaim (1 minute)
    processing_timeout_ms: 600000 # Max time in "processing" state before auto-unclaim (10 minutes)

    # Observability
    status_log_interval_ms: 2000 # Interval for logging daemon status (set to null to disable)

  # Files configuration for batch file uploads/downloads
  files:
    max_file_size: 2147483648 # 2 GB - maximum size for file uploads
    upload_buffer_size: 100 # Buffer size for file upload streams (default: 100)
    download_buffer_size: 100 # Buffer size for file download streams (default: 100)

